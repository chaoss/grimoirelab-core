# -*- coding: utf-8 -*-
#
# Copyright (C) GrimoireLab Contributors
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.
#

from __future__ import annotations

import logging
import typing

import cloudevents.conversion
import rq.job

import perceval.backend
import perceval.backends
import chronicler.eventizer

from .errors import NotFoundError

if typing.TYPE_CHECKING:
    from typing import Any, Optional
    from logging import LogRecord
    from rq.types import FunctionReferenceType


logger = logging.getLogger(__name__)


class GrimoireLabJob(rq.job.Job):
    """Abstract class to execute jobs for GrimoireLab.

    This class is a wrapper around the RQ job class to run jobs
    for GrimoireLab. It adds some extra functionality such as
    logging and progress handling. The log entries generated
    by the job can be accessed through the property `log`.

    To create an instance of this class, you must use the
    classmethod `create`. This method ensures that all the elements
    needed to run a job are properly set up.
    """

    # Default packages to log
    PACKAGES_TO_LOG = [__name__, 'chronicler', 'perceval', 'rq']

    def __init__(self, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self.job_logger = JobLogHandler(self)
        self._loggers = self.PACKAGES_TO_LOG
        self.meta['log'] = []
        self.meta['progress'] = None

    @classmethod
    def create(cls, func: FunctionReferenceType,
               loggers: list[str] | None = None,
               *args, **kwargs) -> GrimoireLabJob:
        """Creates a new GrimoireLabJob instance.

        :param loggers: list of packages or modules to log; by default,
            the job will log the messages generated by the packages
            set on `PACKAGES_TO_LOG`. This list will be overridden
            by any list passed as argument.
        """
        # Make sure meta parameters are initialized.
        # If not given, they will be overridden on the initialization
        # of the Job class parent.
        kwargs['meta'] = {'log': [], 'progress': None}
        job = super().create(func, *args, **kwargs)

        job.job_logger = JobLogHandler(job)
        job._loggers = loggers if loggers else job.PACKAGES_TO_LOG

        return job

    @property
    def progress(self) -> Any:
        """Returns the progress of the job."""

        return self.meta.get('progress', None)

    @progress.setter
    def progress(self, value: Any) -> None:
        """Set the progress of the job."""

        self.meta['progress'] = value
        self.save_meta()

    @property
    def log(self) -> list[dict[str, Any]] | None:
        """Returns the log of the job."""

        return self.meta.get('log', [])

    def _add_log_handler(self):
        """Add the log handler to the job."""
        for logger_name in self._loggers:
            logger_job = logging.getLogger(logger_name)
            logger_job.setLevel(logging.INFO)
            logger_job.addHandler(self.job_logger)

    def _remove_log_handler(self):
        """Remove the log handler from the job"""

        for logger_name in self._loggers:
            logger_job = logging.getLogger(logger_name)
            logger_job.removeHandler(self.job_logger)

    def _execute(self) -> Any:
        """Run the job."""

        try:
            self._add_log_handler()
            return super()._execute()
        finally:
            self._remove_log_handler()


class JobLogHandler(logging.StreamHandler):
    """Handler class for the job logs.

    Log entries will be stored in the job metadata.

    :param job: job to store the logs
    """
    def __init__(self, job: GrimoireLabJob) -> None:
        logging.StreamHandler.__init__(self)
        self.job = job
        self.job.meta['log'] = []
        self.job.save_meta()

    def emit(self, record: LogRecord) -> None:
        """Emit a log entry storing it in the job metadata.

        :param record: log record to emit
        """
        log = {
            'created': record.created,
            'msg': self.format(record),
            'module': record.module,
            'level': self.level,
        }
        self.job.meta['log'].append(log)
        self.job.save_meta()


def chronicler_job(datasource_type: str,
                   datasource_category: str,
                   events_queue: str,
                   job_args: dict[str, Any] = None):
    """Fetch and eventize data.

    It will fetch data from a software development repository and
    convert it into events. Fetched data and events will be
    published to a Redis queue. The progress of the job can be accessed
    through the property `progress`. The result of the job can be obtained
    accessing to the property `result` of the object.

    Data will be fetched using `perceval` and eventized using
    `chronicler`.

    :param datasource_type: type of the datasource
        (e.g., 'git', 'github')
    :param datasource_category: category of the datasource
        (e.g., 'pull_request', 'issue')
    :param job_args: extra arguments to pass to the job
        (e.g., 'url', 'owner', 'repository')
    """
    rq_job = rq.get_current_job()

    try:
        backends = perceval.backend.find_backends(perceval.backends)[0]
        backend_klass = backends[datasource_type]
    except KeyError:
        raise NotFoundError(element=datasource_type)

    backend_args = job_args.copy() if job_args else {}

    # Get the generator to fetch the data items
    perceval_gen = perceval.backend.BackendItemsGenerator(backend_klass,
                                                          backend_args,
                                                          datasource_category)
    progress = ChroniclerProgress(rq_job.get_id(),
                                  datasource_type,
                                  datasource_category,
                                  None)
    rq_job.progress = progress

    # The chronicler generator will eventize the data items
    # that are fetched by the perceval generator.
    try:
        events = chronicler.eventizer.eventize(datasource_type,
                                               perceval_gen.items)
        for event in events:
            data = cloudevents.conversion.to_json(event)
            rq_job.connection.rpush(events_queue, data)
    finally:
        progress.summary = perceval_gen.summary

    return progress


class ChroniclerProgress:
    """Class to store the progress of a Chronicler job.

    It stores the summary of the job and other useful data
    such as the task and job identifiers, the backend and the
    category of the items generated.

    :param job_id: job identifier
    :param backend: backend used to fetch the items
    :param category: category of the fetched items
    """
    def __init__(self, job_id: str, backend: str, category: str,
                 summary: Optional[perceval.backend.Summary] = None):
        self.job_id = job_id
        self.backend = backend
        self.category = category
        self.summary = summary

    def to_dict(self) -> dict[str, str | int]:
        """Convert object to a dict."""

        result = {
            'job_id': self.job_id,
        }

        if self.summary:
            result['fetched'] = self.summary.fetched
            result['skipped'] = self.summary.skipped
            result['last_uuid'] = self.summary.last_uuid
            result['min_offset'] = self.summary.min_offset
            result['max_offset'] = self.summary.max_offset
            result['last_offset'] = self.summary.last_offset
            result['extras'] = self.summary.extras
            if self.summary.min_updated_on:
                result['min_updated_on'] = self.summary.min_updated_on.timestamp()
            else:
                result['min_updated_on'] = None
            if self.summary.max_updated_on:
                result['max_updated_on'] = self.summary.max_updated_on.timestamp()
            else:
                result['max_updated_on'] = None
            if self.summary.last_updated_on:
                result['last_updated_on'] = self.summary.last_updated_on.timestamp()
            else:
                result['last_updated_on'] = None

        return result
